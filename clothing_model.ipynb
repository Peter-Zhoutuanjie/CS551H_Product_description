{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f21cc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !pip install git+https://github.com/huggingface/datasets.git\n",
    "# !pip install rouge_score\n",
    "# !pip install sentencepiece\n",
    "# !pip install transformers\n",
    "# !pip install bert_score\n",
    "# !pip install seaborn\n",
    "# !pip3 install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc4ae8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM, Seq2SeqTrainer, Seq2SeqTrainingArguments,T5Model\n",
    ")\n",
    "from datasets import load_dataset\n",
    "from transformers import T5Tokenizer\n",
    "from datasets import load_metric\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "\n",
    "from transformers import T5Tokenizer\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict\n",
    "import datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec7d6b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "BEAM_SIZE = 4\n",
    "DEVICE = \"cpu\"\n",
    "MODEL_NAME = \"google/t5-v1_1-base\"\n",
    "DATASET_NAME = \"e2e_nlg\"\n",
    "MAX_LENGTH = 512\n",
    "BATCH_SIZE = 12\n",
    "SAVE_EVAL_STRATEGY = 'epoch'\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8f473d",
   "metadata": {},
   "source": [
    "loading the data and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be7009a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Women_Boohoo_UK_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f15b5e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1800 entries, 0 to 1801\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   name        1800 non-null   object\n",
      " 1   gender      1800 non-null   object\n",
      " 2   attributes  1279 non-null   object\n",
      " 3   colour      1800 non-null   object\n",
      " 4   price       1800 non-null   object\n",
      " 5   category    1800 non-null   object\n",
      " 6   desc        1800 non-null   object\n",
      "dtypes: object(7)\n",
      "memory usage: 112.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data = data.dropna(subset=['desc'])\n",
    "data = data.dropna(subset=['name'])\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48de785f",
   "metadata": {},
   "source": [
    "split training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "604ba269",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['source'] = 'name[' + data['name'] + '] gender[' + data[\n",
    "    'gender'] + '] colour[' + data['colour'] + '] price[' + data[\n",
    "        'price'] + '] category[' + data['category'] + '] '\n",
    "data = data.drop(\n",
    "    ['name', 'gender', 'attributes', 'colour', 'price', 'category'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "913a38ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A classic wardrobe staple which no clothing co...</td>\n",
       "      <td>name[High Waisted Disco Denim Shorts] gender[f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If youâ€™re going for a top-to-bottom wardrobe r...</td>\n",
       "      <td>name[Black Crew Neck Basic Cotton Tshirt] gend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hit refresh on your casual wardrobe with a ver...</td>\n",
       "      <td>name[Faux Leather Trucker Jacket] gender[femal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A seriously comfy addition to your new-season ...</td>\n",
       "      <td>name[Cropped Slouchy Hoodie] gender[female] co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A menswear classic with a feminine edge, add a...</td>\n",
       "      <td>name[Pinstripe Tie Waist Fitted Tailored Blaze...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>Introducing your new fave top from our latest ...</td>\n",
       "      <td>name[Plus Bandage Hook And Eye Corset Top] gen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>Introducing your new fave top from our latest ...</td>\n",
       "      <td>name[Beige Plus Oversized Basic Sweatshirt] ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>Swapping out your jeans for something comfier?...</td>\n",
       "      <td>name[Beige Plus Double Cargo Pocket Oversized ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1800</th>\n",
       "      <td>Just chilling? Do it right with an oversized h...</td>\n",
       "      <td>name[Dsgn Studio Slogan Oversized Hoodie] gend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1801</th>\n",
       "      <td>Introducing your new fave top from our latest ...</td>\n",
       "      <td>name[Plus Barbie Palm Tree Washed T-shirt] gen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1800 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   desc  \\\n",
       "0     A classic wardrobe staple which no clothing co...   \n",
       "1     If youâ€™re going for a top-to-bottom wardrobe r...   \n",
       "2     Hit refresh on your casual wardrobe with a ver...   \n",
       "3     A seriously comfy addition to your new-season ...   \n",
       "4     A menswear classic with a feminine edge, add a...   \n",
       "...                                                 ...   \n",
       "1797  Introducing your new fave top from our latest ...   \n",
       "1798  Introducing your new fave top from our latest ...   \n",
       "1799  Swapping out your jeans for something comfier?...   \n",
       "1800  Just chilling? Do it right with an oversized h...   \n",
       "1801  Introducing your new fave top from our latest ...   \n",
       "\n",
       "                                                 source  \n",
       "0     name[High Waisted Disco Denim Shorts] gender[f...  \n",
       "1     name[Black Crew Neck Basic Cotton Tshirt] gend...  \n",
       "2     name[Faux Leather Trucker Jacket] gender[femal...  \n",
       "3     name[Cropped Slouchy Hoodie] gender[female] co...  \n",
       "4     name[Pinstripe Tie Waist Fitted Tailored Blaze...  \n",
       "...                                                 ...  \n",
       "1797  name[Plus Bandage Hook And Eye Corset Top] gen...  \n",
       "1798  name[Beige Plus Oversized Basic Sweatshirt] ge...  \n",
       "1799  name[Beige Plus Double Cargo Pocket Oversized ...  \n",
       "1800  name[Dsgn Studio Slogan Oversized Hoodie] gend...  \n",
       "1801  name[Plus Barbie Palm Tree Washed T-shirt] gen...  \n",
       "\n",
       "[1800 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d969d0c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A classic wardrobe staple which no clothing co...</td>\n",
       "      <td>name[High Waisted Disco Denim Shorts] gender[f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If youâ€™re going for a top-to-bottom wardrobe r...</td>\n",
       "      <td>name[Black Crew Neck Basic Cotton Tshirt] gend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hit refresh on your casual wardrobe with a ver...</td>\n",
       "      <td>name[Faux Leather Trucker Jacket] gender[femal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A seriously comfy addition to your new-season ...</td>\n",
       "      <td>name[Cropped Slouchy Hoodie] gender[female] co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A menswear classic with a feminine edge, add a...</td>\n",
       "      <td>name[Pinstripe Tie Waist Fitted Tailored Blaze...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                desc  \\\n",
       "0  A classic wardrobe staple which no clothing co...   \n",
       "1  If youâ€™re going for a top-to-bottom wardrobe r...   \n",
       "2  Hit refresh on your casual wardrobe with a ver...   \n",
       "3  A seriously comfy addition to your new-season ...   \n",
       "4  A menswear classic with a feminine edge, add a...   \n",
       "\n",
       "                                              source  \n",
       "0  name[High Waisted Disco Denim Shorts] gender[f...  \n",
       "1  name[Black Crew Neck Basic Cotton Tshirt] gend...  \n",
       "2  name[Faux Leather Trucker Jacket] gender[femal...  \n",
       "3  name[Cropped Slouchy Hoodie] gender[female] co...  \n",
       "4  name[Pinstripe Tie Waist Fitted Tailored Blaze...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14abdaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = data.iloc[:1700]   # First two rows of the dataframe\n",
    "df_test = data.iloc[1700:]   # Remaining rows of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19691011",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_train_test = DatasetDict({\n",
    "    \"train\": Dataset.from_pandas(df_train),\n",
    "    \"test\": Dataset.from_pandas(df_test)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f933380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['desc', 'source', '__index_level_0__'],\n",
       "        num_rows: 1700\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['desc', 'source', '__index_level_0__'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92052a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name[High Waisted Disco Denim Shorts] gender[female] colour[mid wash] price[Â£12.00] category[SHORTS] \n"
     ]
    }
   ],
   "source": [
    "print(datasets_train_test['train'][0]['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e8c1ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_input_for_batch(batch):\n",
    "    \"\"\"Construct input strings from a batch.\"\"\"\n",
    "#     print(len(batch[\"source\"]))\n",
    "    source = batch[\"source\"]\n",
    "    target = batch[\"desc\"]\n",
    "    return source, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f35126e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_tokenize(batch, tokenizer, max_length=32):\n",
    "    \"\"\"Construct the batch (source, target) and run them through a tokenizer.\"\"\"\n",
    "    source, target = construct_input_for_batch(batch)\n",
    "    target_tokenized = tokenizer(\n",
    "            batch['desc'],\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=150\n",
    "        )\n",
    "    target_input_ids = target_tokenized['input_ids']\n",
    "    \n",
    "    res = {\n",
    "        \"input_ids\": tokenizer(source,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=max_length)[\"input_ids\"],\n",
    "        \"labels\": target_input_ids,\n",
    "    }\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9f275a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1700 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "train_data_tokenized = datasets_train_test['train'].map(\n",
    "    lambda batch: batch_tokenize(batch, tokenizer, max_length=MAX_LENGTH),\n",
    "    batched=True\n",
    ")\n",
    "valid_data_tokenized = datasets_train_test['test'].map(\n",
    "    lambda batch: batch_tokenize(batch, tokenizer, max_length=MAX_LENGTH),\n",
    "    batched=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "528829da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4158/1771409562.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  meteor_scorer = load_metric('meteor')\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "meteor_scorer = load_metric('meteor')\n",
    "\n",
    "def meteor_metric_builder(tokenizer):\n",
    "    def compute_meteor_metrics(pred):\n",
    "        \"\"\"Utility to compute meteor during training.\"\"\"\n",
    "        labels_ids = pred.label_ids\n",
    "        pred_ids = pred.predictions\n",
    "        # All special tokens are removed.\n",
    "        pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "        labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n",
    "        label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "        # Compute the metric.\n",
    "        meteor_results = meteor_scorer.compute(predictions=pred_str,\n",
    "                                       references=label_str)\n",
    "        return {\n",
    "            \"meteor\": round(meteor_results['meteor'], 4),\n",
    "        }\n",
    "    return compute_meteor_metrics\n",
    "\n",
    "meteor_metric_fn = meteor_metric_builder(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ef9398b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    DEVICE = torch.ones(1, device=mps_device)\n",
    "    print(DEVICE)\n",
    "elif torch.cuda.is_available():\n",
    "    DEVICE = \"cuda:0\"\n",
    "    print(DEVICE)\n",
    "    \n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "696c08e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"t5-v1_1-base-Clothing\",\n",
    "    evaluation_strategy=SAVE_EVAL_STRATEGY,\n",
    "    save_strategy=SAVE_EVAL_STRATEGY,\n",
    "    logging_steps=5,\n",
    "    # optimization args, the trainer uses the Adam optimizer\n",
    "    # and has a linear warmup for the learning rate\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=1,\n",
    "    learning_rate=1e-03,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    warmup_steps=1000,\n",
    "    # misc args\n",
    "    seed=RANDOM_SEED,\n",
    "    disable_tqdm=False,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"meteor\",\n",
    "    # generation\n",
    "    predict_with_generate=True,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=train_args,\n",
    "    train_dataset=train_data_tokenized,\n",
    "    eval_dataset=valid_data_tokenized,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=meteor_metric_fn,\n",
    ")\n",
    "\n",
    "trainer._max_length = MAX_LENGTH\n",
    "trainer._num_beams = BEAM_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a503eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: desc, __index_level_0__, source. If desc, __index_level_0__, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1700\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 12\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 12\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1420\n",
      "  Number of trainable parameters = 247577856\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='614' max='1420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 614/1420 05:07 < 06:44, 1.99 it/s, Epoch 4.32/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Meteor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.160400</td>\n",
       "      <td>3.796676</td>\n",
       "      <td>0.006600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.072800</td>\n",
       "      <td>1.308939</td>\n",
       "      <td>0.055500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.395400</td>\n",
       "      <td>0.724753</td>\n",
       "      <td>0.015000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.568500</td>\n",
       "      <td>0.680771</td>\n",
       "      <td>0.075300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: desc, __index_level_0__, source. If desc, __index_level_0__, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 12\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Saving model checkpoint to t5-v1_1-base-Clothing/checkpoint-142\n",
      "Configuration saved in t5-v1_1-base-Clothing/checkpoint-142/config.json\n",
      "Configuration saved in t5-v1_1-base-Clothing/checkpoint-142/generation_config.json\n",
      "Model weights saved in t5-v1_1-base-Clothing/checkpoint-142/pytorch_model.bin\n",
      "tokenizer config file saved in t5-v1_1-base-Clothing/checkpoint-142/tokenizer_config.json\n",
      "Special tokens file saved in t5-v1_1-base-Clothing/checkpoint-142/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: desc, __index_level_0__, source. If desc, __index_level_0__, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 12\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Saving model checkpoint to t5-v1_1-base-Clothing/checkpoint-284\n",
      "Configuration saved in t5-v1_1-base-Clothing/checkpoint-284/config.json\n",
      "Configuration saved in t5-v1_1-base-Clothing/checkpoint-284/generation_config.json\n",
      "Model weights saved in t5-v1_1-base-Clothing/checkpoint-284/pytorch_model.bin\n",
      "tokenizer config file saved in t5-v1_1-base-Clothing/checkpoint-284/tokenizer_config.json\n",
      "Special tokens file saved in t5-v1_1-base-Clothing/checkpoint-284/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: desc, __index_level_0__, source. If desc, __index_level_0__, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 12\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Saving model checkpoint to t5-v1_1-base-Clothing/checkpoint-426\n",
      "Configuration saved in t5-v1_1-base-Clothing/checkpoint-426/config.json\n",
      "Configuration saved in t5-v1_1-base-Clothing/checkpoint-426/generation_config.json\n",
      "Model weights saved in t5-v1_1-base-Clothing/checkpoint-426/pytorch_model.bin\n",
      "tokenizer config file saved in t5-v1_1-base-Clothing/checkpoint-426/tokenizer_config.json\n",
      "Special tokens file saved in t5-v1_1-base-Clothing/checkpoint-426/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: desc, __index_level_0__, source. If desc, __index_level_0__, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 12\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Saving model checkpoint to t5-v1_1-base-Clothing/checkpoint-568\n",
      "Configuration saved in t5-v1_1-base-Clothing/checkpoint-568/config.json\n",
      "Configuration saved in t5-v1_1-base-Clothing/checkpoint-568/generation_config.json\n",
      "Model weights saved in t5-v1_1-base-Clothing/checkpoint-568/pytorch_model.bin\n",
      "tokenizer config file saved in t5-v1_1-base-Clothing/checkpoint-568/tokenizer_config.json\n",
      "Special tokens file saved in t5-v1_1-base-Clothing/checkpoint-568/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84283651",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_generate_sentences(batch,\n",
    "                            model,\n",
    "                            tokenizer,\n",
    "                            num_beams=4,\n",
    "                            max_length=128,\n",
    "                            device='cuda:0'):\n",
    "    \"\"\"Generate outputs from a model with beam search decoding.\"\"\"\n",
    "    # Create batch inputs.\n",
    "    source, _ = construct_input_for_batch(batch)\n",
    "    # Use the model's tokenizer to create the batch input_ids.\n",
    "    batch_features = tokenizer(source, padding=True, return_tensors='pt')\n",
    "    # Move all inputs to the device.\n",
    "    batch_features = dict([(k, v.to(device))\n",
    "                           for k, v in batch_features.items()])\n",
    "\n",
    "    # Generate with beam search.\n",
    "    generated_ids = model.generate(\n",
    "        **batch_features,\n",
    "        num_beams=num_beams,\n",
    "        max_length=max_length,\n",
    "    )\n",
    "\n",
    "    # Use model tokenizer to decode to text.\n",
    "    generated_sentences = [\n",
    "        tokenizer.decode(gen_ids.tolist(), skip_special_tokens=True)\n",
    "        for gen_ids in generated_ids\n",
    "    ]\n",
    "    return generated_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d389dfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_output = datasets_train_test['test'].map(\n",
    "    lambda batch: {\n",
    "        'generated':\n",
    "        beam_generate_sentences(batch,\n",
    "                                model,\n",
    "                                tokenizer,\n",
    "                                num_beams=BEAM_SIZE,\n",
    "                                max_length=MAX_LENGTH,\n",
    "                                device=DEVICE)\n",
    "    },\n",
    "    batched=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28976a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate for ROUGE-2/L\n",
    "rouge_scorer = load_metric(\"rouge\")\n",
    "\n",
    "rouge_results = rouge_scorer.compute(\n",
    "    predictions=valid_output[\"generated\"],\n",
    "    references=valid_output[\"desc\"],\n",
    "    rouge_types=[\"rougeL\"],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=False,\n",
    ")\n",
    "rougeL = rouge_results['rougeL'].mid.fmeasure\n",
    "f\"R-L: {rouge_results['rougeL'].mid.fmeasure:.3f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67d8ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f729d9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate for meteor\n",
    "\n",
    "meteor_results = meteor_scorer.compute(predictions=valid_output[\"generated\"],\n",
    "                                       references=valid_output[\"desc\"])\n",
    "meteor = meteor_results['meteor']\n",
    "meteor_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a245ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "bertscore = load_metric(\"bertscore\")\n",
    "bertscore_results = bertscore.compute(predictions=valid_output[\"generated\"],\n",
    "                                      references=valid_output[\"desc\"],\n",
    "                                      model_type='distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f7cb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "bertscore_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a1c8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average(lst):\n",
    "    return sum(lst) / len(lst)\n",
    "\n",
    "bert_average_precision = average(bertscore_results['precision'])\n",
    "bert_average_recall = average(bertscore_results['recall'])\n",
    "bert_average_f1 = average(bertscore_results['f1'])\n",
    "\n",
    "f'average_precision: {bert_average_precision}, average_recall: {bert_average_recall},average_f1: {bert_average_f1}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c310f771",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_score_merics = [\n",
    "    \"rougeL\", \"meteor\", \"bert_average_precision\", \"bert_average_recall\",\n",
    "    \"bert_average_f1\"\n",
    "]\n",
    "bert_score_list = [\n",
    "    rougeL, meteor, bert_average_precision, bert_average_recall,\n",
    "    bert_average_f1\n",
    "]\n",
    "\n",
    "dataf = pd.DataFrame({\n",
    "    \"bert_score_merics\": bert_score_merics,\n",
    "    \"bert_score_list\": bert_score_list\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(12, 6), dpi=80)\n",
    "sns.barplot(x=\"bert_score_merics\",\n",
    "            y=\"bert_score_list\",\n",
    "            data=dataf,\n",
    "            palette='Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87809d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.choice(valid_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607200a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9562d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b591b866",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac23cf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199c5fd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a05cb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8550abf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211f7872",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d17bab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3588a168",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941f69e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffdaa3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476a7d57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23cf662",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fed1f52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d4d35a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5a39c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c264e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1347d9c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
